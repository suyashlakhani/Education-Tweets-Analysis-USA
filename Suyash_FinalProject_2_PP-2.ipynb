{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb3fb3d-acd2-48ba-b636-4b461406333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Reading the filtered parquet file\n",
    "tw_df = spark.read.parquet(\"gs://msca-bdp-students-bucket/shared_data/suyashlakhani/tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce83a996-badc-4201-a7b9-286902c59706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:======================================================>(986 + 1) / 987]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91182863 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(tw_df.count(),len(tw_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adad4ecc-3645-4c17-a820-8860b18e650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "pd.set_option(\"max_colwidth\", 100)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait = False)\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6101426-ccb9-43a3-8776-872aa362aae6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/04 19:17:47 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 27 for reason Container marked as failed: container_1670090078315_0006_01_000028 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-wwx8.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n",
      "22/12/04 19:17:47 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 28 for reason Container marked as failed: container_1670090078315_0006_01_000029 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-wwx8.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n",
      "22/12/04 19:17:47 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 27 on hub-msca-bdp-dphub-students-suyashlakhani-sw-wwx8.c.msca-bdp-students.internal: Container marked as failed: container_1670090078315_0006_01_000028 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-wwx8.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n",
      "22/12/04 19:17:47 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 28 on hub-msca-bdp-dphub-students-suyashlakhani-sw-wwx8.c.msca-bdp-students.internal: Container marked as failed: container_1670090078315_0006_01_000029 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-wwx8.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n",
      "22/12/04 19:25:03 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 8.0 (TID 2127) (hub-msca-bdp-dphub-students-suyashlakhani-sw-xzqw.c.msca-bdp-students.internal executor 26): FetchFailed(BlockManagerId(28, hub-msca-bdp-dphub-students-suyashlakhani-sw-wwx8.c.msca-bdp-students.internal, 7337, None), shuffleId=2, mapIndex=8, mapId=1144, reduceId=0, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=7558554000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670090078315_0006, execId=28)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getBlockData(ExternalShuffleBlockResolver.java:170)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:479)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n",
      "\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n",
      "\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:775)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=7558554000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670090078315_0006, execId=28)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getBlockData(ExternalShuffleBlockResolver.java:170)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:479)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n",
      "\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n",
      "\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "22/12/04 19:26:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 8.1 (TID 2250) (hub-msca-bdp-dphub-students-suyashlakhani-sw-xzqw.c.msca-bdp-students.internal executor 26): FetchFailed(BlockManagerId(27, hub-msca-bdp-dphub-students-suyashlakhani-sw-wwx8.c.msca-bdp-students.internal, 7337, None), shuffleId=2, mapIndex=5, mapId=1141, reduceId=0, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=7558554006,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670090078315_0006, execId=27)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getBlockData(ExternalShuffleBlockResolver.java:170)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:479)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n",
      "\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n",
      "\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:775)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=7558554006,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670090078315_0006, execId=27)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getBlockData(ExternalShuffleBlockResolver.java:170)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:479)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n",
      "\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n",
      "\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n",
      "\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31523500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_df_filt = tw_df.filter(\n",
    "                          (lower(col('text')).contains(\"children\"))\\\n",
    "                          | (lower(col('text')).contains(\"kindergraden\"))\\\n",
    "                          | (lower(col('text')).contains(\"testing\"))\\\n",
    "                          | (lower(col('text')).contains(\"grade\"))\\\n",
    "                          | (lower(col('text')).contains(\"student\"))\\\n",
    "                          | (lower(col('text')).contains(\"grades\"))\\\n",
    "                          | (lower(col('text')).contains(\"education\"))\\\n",
    "                          | (lower(col('text')).contains(\"k12\"))\\\n",
    "                          | (lower(col('text')).contains(\"high school\"))\\\n",
    "                          | (lower(col('text')).contains(\"college\"))\\\n",
    "                          | (lower(col('text')).contains(\"elementary school\"))\\\n",
    "                          | (lower(col('text')).contains(\"online education\"))\\\n",
    "                          | (lower(col('text')).contains(\"math\"))\\\n",
    "                          | (lower(col('text')).contains(\"science\"))\\\n",
    "                          | (lower(col('text')).contains(\"k-12\"))\\\n",
    "                          | (lower(col('text')).contains(\"middle school\"))\n",
    "                          | (lower(col('text')).contains(\"curriculum\"))\\\n",
    "                          | (lower(col('text')).contains(\"learning\"))\\\n",
    "                          | (lower(col('text')).contains(\"colleges\"))\\\n",
    "                          | (lower(col('text')).contains(\"tuition\"))\\\n",
    "                          | (lower(col('text')).contains(\"primary school\"))\n",
    "                          \n",
    "                          & ~(lower(col('text')).contains(\"shot\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"kill\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"murder\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"murdered\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"shoot\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"killed\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"killing\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"attack\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"attacked\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"gun\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"weapon\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"sex\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"porn\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"tounament\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"weapons\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"massacre\"))\\\n",
    "                          & ~(lower(col('text')).contains(\"dead\"))\n",
    "                          )\n",
    "\n",
    "tw_df_filt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15ee093-c86e-4355-af08-387a8553ad91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tw_df_filt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bcf8f51-b727-4b29-b0f8-eff8049df5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>created_at</th><th>display_text_range</th><th>entities</th><th>favorite_count</th><th>favorited</th><th>filter_level</th><th>is_quote_status</th><th>lang</th><th>place</th><th>possibly_sensitive</th><th>quote_count</th><th>reply_count</th><th>retweet_count</th><th>retweeted</th><th>retweeted_from</th><th>retweeted_status</th><th>source</th><th>text</th><th>timestamp_ms</th><th>truncated</th><th>tweet_text</th><th>user</th></tr>\n",
       "<tr><td>Thu Jun 16 20:04:...</td><td>[15, 140]</td><td>{[], null, [], [{...</td><td>0</td><td>false</td><td>low</td><td>false</td><td>en</td><td>null</td><td>false</td><td>0</td><td>0</td><td>0</td><td></td><td>null</td><td>null</td><td>&lt;a href=&quot;http://t...</td><td>@asamiamihoops Tr...</td><td>1655409847488</td><td>true</td><td>@asamiamihoops Tr...</td><td>{false, Fri Feb 2...</td></tr>\n",
       "<tr><td>Thu Jun 16 20:04:...</td><td>null</td><td>{[], null, [], []...</td><td>0</td><td>false</td><td>low</td><td>false</td><td>en</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>RT</td><td>itsJeffTiedrich</td><td>{null, Thu Jun 16...</td><td>&lt;a href=&quot;http://t...</td><td>RT @itsJeffTiedri...</td><td>1655409847581</td><td>false</td><td>fun true fact: mo...</td><td>{false, Mon Nov 0...</td></tr>\n",
       "<tr><td>Thu Jun 16 20:04:...</td><td>null</td><td>{[], null, [], []...</td><td>0</td><td>false</td><td>low</td><td>false</td><td>en</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>RT</td><td>ReallyAmerican1</td><td>{null, Thu Jun 16...</td><td>&lt;a href=&quot;https://...</td><td>RT @ReallyAmerica...</td><td>1655409848522</td><td>false</td><td>Who else agrees t...</td><td>{false, Thu Jan 2...</td></tr>\n",
       "<tr><td>Thu Jun 16 20:04:...</td><td>null</td><td>{[], null, [], []...</td><td>0</td><td>false</td><td>low</td><td>false</td><td>en</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>RT</td><td>DCUIntl</td><td>{null, Thu Jun 16...</td><td>&lt;a href=&quot;http://t...</td><td>RT @DCUIntl: Cong...</td><td>1655409848823</td><td>false</td><td>Congrats to all o...</td><td>{false, Mon Dec 2...</td></tr>\n",
       "<tr><td>Thu Jun 16 20:04:...</td><td>null</td><td>{[], null, [], []...</td><td>0</td><td>false</td><td>low</td><td>false</td><td>en</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>RT</td><td>judgejules75</td><td>{null, Thu Jun 16...</td><td>&lt;a href=&quot;http://t...</td><td>RT @judgejules75:...</td><td>1655409849853</td><td>false</td><td>Other orgs to end...</td><td>{false, Mon Jun 1...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+------------------+--------------------+--------------+---------+------------+---------------+----+-----+------------------+-----------+-----------+-------------+---------+--------------+--------------------+--------------------+--------------------+-------------+---------+--------------------+--------------------+\n",
       "|          created_at|display_text_range|            entities|favorite_count|favorited|filter_level|is_quote_status|lang|place|possibly_sensitive|quote_count|reply_count|retweet_count|retweeted|retweeted_from|    retweeted_status|              source|                text| timestamp_ms|truncated|          tweet_text|                user|\n",
       "+--------------------+------------------+--------------------+--------------+---------+------------+---------------+----+-----+------------------+-----------+-----------+-------------+---------+--------------+--------------------+--------------------+--------------------+-------------+---------+--------------------+--------------------+\n",
       "|Sat Aug 13 17:09:...|           [0, 90]|{[{[72, 90], West...|             0|    false|         low|          false|  en| null|             false|          0|          0|            0|         |          null|                null|<a href=\"https://...|Kaza Nishiba,MIF,...|1660410566593|    false|Kaza Nishiba,MIF,...|{false, Wed Dec 1...|\n",
       "|Sat Aug 13 17:09:...|              null|{[], null, [], []...|             0|    false|         low|          false|  en| null|              null|          0|          0|            0|         |          null|                null|<a href=\"http://t...|im 97% sure that ...|1660410567981|    false|im 97% sure that ...|{false, Wed Aug 1...|\n",
       "|Sat Aug 13 17:09:...|              null|{[], null, [], []...|             0|    false|         low|          false|  en| null|              null|          0|          0|            0|       RT|engineers_feed|{null, Sat Aug 13...|<a href=\"http://t...|RT @engineers_fee...|1660410569294|    false|Those photos of s...|{false, Sat Oct 1...|\n",
       "|Sat Aug 13 17:09:...|              null|{[{[4, 10], gaunt...|             0|    false|         low|          false|  en| null|              null|          0|          0|            0|         |          null|                null|<a href=\"http://t...|The #gaunt hallwa...|1660410569539|     true|The #gaunt hallwa...|{false, Mon Nov 1...|\n",
       "|Sat Aug 13 17:09:...|              null|{[], null, [], []...|             0|    false|         low|          false|  en| null|              null|          0|          0|            0|         |          null|                null|<a href=\"http://t...|A lot of you stil...|1660410569943|    false|A lot of you stil...|{false, Sun Dec 2...|\n",
       "+--------------------+------------------+--------------------+--------------+---------+------------+---------------+----+-----+------------------+-----------+-----------+-------------+---------+--------------+--------------------+--------------------+--------------------+-------------+---------+--------------------+--------------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_df_filt.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ef02cfa-9511-4042-8d6e-b0075bdeca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>country</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "      <th>verified_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 17 17:08:22 +0000 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>(False, Sat May 22 06:33:12 +0000 2021, True, False, None, 3644, 198, 546, False, 13959908890848...</td>\n",
       "      <td>1395990889084817410</td>\n",
       "      <td>1158 APLC Jaskarn Singh</td>\n",
       "      <td>None</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(None, Sat Sep 17 16:00:28 +0000 2022, None, ([], None, [], [Row(display_url='twitter.com/i/web/...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>RT @ArshWariana: Once there used to be good quality govt colleges in Punjab.This statement is go...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Sep 17 17:08:23 +0000 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>(False, Tue Jan 11 16:55:28 +0000 2022, True, False, None, 34421, 50, 118, False, 14809463720775...</td>\n",
       "      <td>1480946372077522950</td>\n",
       "      <td>Suren</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>21.0</td>\n",
       "      <td>(None, Fri Sep 16 10:15:57 +0000 2022, [0, 140], ([Row(indices=[0, 9], text='BREAKING')], None, ...</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>5591.0</td>\n",
       "      <td>RT @republic: #BREAKING | My heart goes out to girls who should have been in college but are han...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sat Sep 17 17:08:23 +0000 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>(False, Thu Aug 05 18:44:26 +0000 2021, True, False, (She/her). Pansexual. Postgrad. Research in...</td>\n",
       "      <td>1423354181075673091</td>\n",
       "      <td>Debadrita Saha 🌈</td>\n",
       "      <td>(She/her). Pansexual. Postgrad. Research int. at @decoloniszing. Former research int. @MCRG_CRG....</td>\n",
       "      <td>430</td>\n",
       "      <td>73.0</td>\n",
       "      <td>(None, Fri Sep 16 15:41:50 +0000 2022, None, ([], None, [], [], []), None, None, 1335, False, lo...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>RT @StefanoBloch: Professors. You assign too much reading. It doesn't help. Assign less so stude...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sat Sep 17 17:08:23 +0000 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>(False, Sat Nov 19 19:06:40 +0000 2011, False, False, SPORTS, 0, 151, 16, False, 416481014, 4164...</td>\n",
       "      <td>416481014</td>\n",
       "      <td>HS SPORTS</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamady vs Madison Academy | Today's Michigan High School Football Live Stream\\nWatch live Broadc...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat Sep 17 17:08:24 +0000 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>(False, Fri Dec 30 19:20:02 +0000 2011, True, False, 💜, 16721, 108, 254, False, 450871097, 45087...</td>\n",
       "      <td>450871097</td>\n",
       "      <td>Annabel bacon</td>\n",
       "      <td>💜</td>\n",
       "      <td>108</td>\n",
       "      <td>341.0</td>\n",
       "      <td>(None, Sat Sep 17 01:51:48 +0000 2022, None, ([], None, [], [Row(display_url='twitter.com/i/web/...</td>\n",
       "      <td>6556.0</td>\n",
       "      <td>21797.0</td>\n",
       "      <td>RT @drsimonegold: BREAKING: A senior high school student at Holmes County High School in Florida...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at country  \\\n",
       "0  Sat Sep 17 17:08:22 +0000 2022    None   \n",
       "1  Sat Sep 17 17:08:23 +0000 2022    None   \n",
       "2  Sat Sep 17 17:08:23 +0000 2022    None   \n",
       "3  Sat Sep 17 17:08:23 +0000 2022    None   \n",
       "4  Sat Sep 17 17:08:24 +0000 2022    None   \n",
       "\n",
       "                                                                                                  user  \\\n",
       "0  (False, Sat May 22 06:33:12 +0000 2021, True, False, None, 3644, 198, 546, False, 13959908890848...   \n",
       "1  (False, Tue Jan 11 16:55:28 +0000 2022, True, False, None, 34421, 50, 118, False, 14809463720775...   \n",
       "2  (False, Thu Aug 05 18:44:26 +0000 2021, True, False, (She/her). Pansexual. Postgrad. Research in...   \n",
       "3  (False, Sat Nov 19 19:06:40 +0000 2011, False, False, SPORTS, 0, 151, 16, False, 416481014, 4164...   \n",
       "4  (False, Fri Dec 30 19:20:02 +0000 2011, True, False, 💜, 16721, 108, 254, False, 450871097, 45087...   \n",
       "\n",
       "               user_id                user_name  \\\n",
       "0  1395990889084817410  1158 APLC Jaskarn Singh   \n",
       "1  1480946372077522950                    Suren   \n",
       "2  1423354181075673091         Debadrita Saha 🌈   \n",
       "3            416481014                HS SPORTS   \n",
       "4            450871097            Annabel bacon   \n",
       "\n",
       "                                                                                      user_description  \\\n",
       "0                                                                                                 None   \n",
       "1                                                                                                 None   \n",
       "2  (She/her). Pansexual. Postgrad. Research int. at @decoloniszing. Former research int. @MCRG_CRG....   \n",
       "3                                                                                               SPORTS   \n",
       "4                                                                                                    💜   \n",
       "\n",
       "   followers_count  quote_count  \\\n",
       "0              198          0.0   \n",
       "1               50         21.0   \n",
       "2              430         73.0   \n",
       "3              151          NaN   \n",
       "4              108        341.0   \n",
       "\n",
       "                                                                                      retweeted_status  \\\n",
       "0  (None, Sat Sep 17 16:00:28 +0000 2022, None, ([], None, [], [Row(display_url='twitter.com/i/web/...   \n",
       "1  (None, Fri Sep 16 10:15:57 +0000 2022, [0, 140], ([Row(indices=[0, 9], text='BREAKING')], None, ...   \n",
       "2  (None, Fri Sep 16 15:41:50 +0000 2022, None, ([], None, [], [], []), None, None, 1335, False, lo...   \n",
       "3                                                                                                 None   \n",
       "4  (None, Sat Sep 17 01:51:48 +0000 2022, None, ([], None, [], [Row(display_url='twitter.com/i/web/...   \n",
       "\n",
       "   retweet_count  favorite_count  \\\n",
       "0           10.0             8.0   \n",
       "1         1156.0          5591.0   \n",
       "2          112.0          1335.0   \n",
       "3            NaN             NaN   \n",
       "4         6556.0         21797.0   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  RT @ArshWariana: Once there used to be good quality govt colleges in Punjab.This statement is go...   \n",
       "1  RT @republic: #BREAKING | My heart goes out to girls who should have been in college but are han...   \n",
       "2  RT @StefanoBloch: Professors. You assign too much reading. It doesn't help. Assign less so stude...   \n",
       "3  Hamady vs Madison Academy | Today's Michigan High School Football Live Stream\\nWatch live Broadc...   \n",
       "4  RT @drsimonegold: BREAKING: A senior high school student at Holmes County High School in Florida...   \n",
       "\n",
       "   verified_user  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting important information from the columns and selecting only the required columns required for analysis\n",
    "data_final = tw_df_filt.select([tw_df_filt.created_at,\n",
    "                         tw_df_filt.place.country.alias(\"country\"),\n",
    "                         tw_df_filt.user, \n",
    "                         tw_df_filt.user['id'].alias(\"user_id\"),\n",
    "                         tw_df_filt.user['name'].alias(\"user_name\"), \n",
    "                         tw_df_filt.user['description'].alias(\"user_description\"), \n",
    "                         tw_df_filt.user['followers_count'].alias(\"followers_count\"), \n",
    "                         tw_df_filt.retweeted_status.quote_count.alias(\"quote_count\"),\n",
    "                         tw_df_filt.retweeted_status,\n",
    "                         tw_df_filt.retweeted_status.retweet_count.alias(\"retweet_count\"),\n",
    "                         tw_df_filt.retweeted_status.favorite_count.alias(\"favorite_count\"),\n",
    "                         tw_df_filt.text, \n",
    "                         tw_df_filt.user.verified.alias(\"verified_user\")])\n",
    "\n",
    "data_final.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b5cbdf9-c946-42bc-af0c-4d964e0392fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/04 20:51:01 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1670090078315_0006_01_000036 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-04 20:51:01.210]Container killed on request. Exit code is 143\n",
      "[2022-12-04 20:51:01.211]Container exited with a non-zero exit code 143. \n",
      "[2022-12-04 20:51:01.211]Killed by external signal\n",
      ".\n",
      "22/12/04 20:51:01 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 35 on hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal: Container from a bad node: container_1670090078315_0006_01_000036 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-04 20:51:01.210]Container killed on request. Exit code is 143\n",
      "[2022-12-04 20:51:01.211]Container exited with a non-zero exit code 143. \n",
      "[2022-12-04 20:51:01.211]Killed by external signal\n",
      ".\n",
      "22/12/04 20:51:01 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 35 for reason Container from a bad node: container_1670090078315_0006_01_000036 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-04 20:51:01.210]Container killed on request. Exit code is 143\n",
      "[2022-12-04 20:51:01.211]Container exited with a non-zero exit code 143. \n",
      "[2022-12-04 20:51:01.211]Killed by external signal\n",
      ".\n",
      "22/12/04 20:51:01 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 956.0 in stage 16.0 (TID 5301) (hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal executor 35): ExecutorLostFailure (executor 35 exited caused by one of the running tasks) Reason: Container from a bad node: container_1670090078315_0006_01_000036 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-04 20:51:01.210]Container killed on request. Exit code is 143\n",
      "[2022-12-04 20:51:01.211]Container exited with a non-zero exit code 143. \n",
      "[2022-12-04 20:51:01.211]Killed by external signal\n",
      ".\n",
      "22/12/04 20:51:01 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 950.0 in stage 16.0 (TID 5295) (hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal executor 35): ExecutorLostFailure (executor 35 exited caused by one of the running tasks) Reason: Container from a bad node: container_1670090078315_0006_01_000036 on host: hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-04 20:51:01.210]Container killed on request. Exit code is 143\n",
      "[2022-12-04 20:51:01.211]Container exited with a non-zero exit code 143. \n",
      "[2022-12-04 20:51:01.211]Killed by external signal\n",
      ".\n",
      "22/12/04 20:53:47 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 18.0 (TID 5334) (hub-msca-bdp-dphub-students-suyashlakhani-sw-xzqw.c.msca-bdp-students.internal executor 38): FetchFailed(BlockManagerId(35, hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal, 7337, None), shuffleId=5, mapIndex=0, mapId=4345, reduceId=0, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal:7337\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:775)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal:7337\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "Caused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-suyashlakhani-sw-3dnh.c.msca-bdp-students.internal\n",
      "\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n",
      "\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n",
      "\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n",
      "\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n",
      "\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n",
      "\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n",
      "\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n",
      "\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n",
      "\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n",
      "\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n",
      "\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n",
      "\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n",
      "\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n",
      "\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n",
      "\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\t... 2 more\n",
      "\n",
      ")\n",
      "[Stage 17:=====================================================>(224 + 1) / 225]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31523500 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(data_final.count(),len(data_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79693443-f667-4664-98c9-2864759cabaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>country</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "      <th>verified_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31225884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4601793</td>\n",
       "      <td>0</td>\n",
       "      <td>10374152</td>\n",
       "      <td>10374152</td>\n",
       "      <td>10374152</td>\n",
       "      <td>10374152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_at   country  user  user_id  user_name  user_description  \\\n",
       "0           0  31225884     0        0          0           4601793   \n",
       "\n",
       "   followers_count  quote_count  retweeted_status  retweet_count  \\\n",
       "0                0     10374152          10374152       10374152   \n",
       "\n",
       "   favorite_count  text  verified_user  \n",
       "0        10374152     0              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null = data_final.select([F.count(F.when(data_final[c].isNull(), c)).alias(c) for c in data_final.columns]).toPandas()\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f19a5b1-aabc-44e8-83f6-6d1dcb0b9421",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_final.na.fill(value=0,subset=[\"retweet_count\", \"quote_count\", \"favorite_count\"])\n",
    "data_final = data_final.na.drop(subset = ['user_description'])\n",
    "data_final = data_final.drop(col(\"country\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba41370-7e87-4405-8e5b-defc975b87b6",
   "metadata": {},
   "source": [
    "--> I handled the missing values of the important columns by either dropping the values(if less) or filling it with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bf5b177-c2fa-48ad-8db6-f0b22b65f7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baltimore, MD, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_location\n",
       "0                None\n",
       "1        Central Ohio\n",
       "2                None\n",
       "3  Baltimore, MD, USA\n",
       "4       San Francisco"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "100272ee-f1ba-470b-a572-e7d0a2808acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "      <th>verified_user</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 17 17:08:23 +0000 2022</td>\n",
       "      <td>(False, Thu Aug 05 18:44:26 +0000 2021, True, False, (She/her). Pansexual. Postgrad. Research in...</td>\n",
       "      <td>1423354181075673091</td>\n",
       "      <td>Debadrita Saha 🌈</td>\n",
       "      <td>(She/her). Pansexual. Postgrad. Research int. at @decoloniszing. Former research int. @MCRG_CRG....</td>\n",
       "      <td>430</td>\n",
       "      <td>73</td>\n",
       "      <td>(None, Fri Sep 16 15:41:50 +0000 2022, None, ([], None, [], [], []), None, None, 1335, False, lo...</td>\n",
       "      <td>112</td>\n",
       "      <td>1335</td>\n",
       "      <td>RT @StefanoBloch: Professors. You assign too much reading. It doesn't help. Assign less so stude...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Sep 17 17:08:23 +0000 2022</td>\n",
       "      <td>(False, Sat Nov 19 19:06:40 +0000 2011, False, False, SPORTS, 0, 151, 16, False, 416481014, 4164...</td>\n",
       "      <td>416481014</td>\n",
       "      <td>HS SPORTS</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamady vs Madison Academy | Today's Michigan High School Football Live Stream\\nWatch live Broadc...</td>\n",
       "      <td>False</td>\n",
       "      <td>Central Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sat Sep 17 17:08:24 +0000 2022</td>\n",
       "      <td>(False, Fri Dec 30 19:20:02 +0000 2011, True, False, 💜, 16721, 108, 254, False, 450871097, 45087...</td>\n",
       "      <td>450871097</td>\n",
       "      <td>Annabel bacon</td>\n",
       "      <td>💜</td>\n",
       "      <td>108</td>\n",
       "      <td>341</td>\n",
       "      <td>(None, Sat Sep 17 01:51:48 +0000 2022, None, ([], None, [], [Row(display_url='twitter.com/i/web/...</td>\n",
       "      <td>6556</td>\n",
       "      <td>21797</td>\n",
       "      <td>RT @drsimonegold: BREAKING: A senior high school student at Holmes County High School in Florida...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sat Sep 17 17:08:24 +0000 2022</td>\n",
       "      <td>(False, Thu Mar 12 10:36:22 +0000 2009, True, False, health care admin, happily married, 5 grand...</td>\n",
       "      <td>23929337</td>\n",
       "      <td>Ira Greene 🌊♻️🌐☮️🌈🐰♋✡️</td>\n",
       "      <td>health care admin, happily married, 5 grandkids, progressive ex-hippie Deadhead still wonder wha...</td>\n",
       "      <td>2458</td>\n",
       "      <td>2</td>\n",
       "      <td>(None, Sat Sep 17 16:32:08 +0000 2022, None, ([], None, [], [], []), None, None, 59, False, low,...</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>RT @ungerbn103: Republicans will fund Abortion Bounty Hunters but they won't fund free School Lu...</td>\n",
       "      <td>False</td>\n",
       "      <td>Baltimore, MD, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat Sep 17 17:08:24 +0000 2022</td>\n",
       "      <td>(False, Wed Feb 11 01:06:47 +0000 2009, False, False, Husband, Dog-Dude, Self-deprecating barkee...</td>\n",
       "      <td>20562088</td>\n",
       "      <td>BrianCass</td>\n",
       "      <td>Husband, Dog-Dude, Self-deprecating barkeep of @noirloungesf SFBay. @warriors @sfgiants @49ers</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@stoolpresidente Has a college QB ever had such a Cliff dive than Rattler.  Wasn’t he in the con...</td>\n",
       "      <td>False</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Sat Sep 17 17:08:23 +0000 2022   \n",
       "1  Sat Sep 17 17:08:23 +0000 2022   \n",
       "2  Sat Sep 17 17:08:24 +0000 2022   \n",
       "3  Sat Sep 17 17:08:24 +0000 2022   \n",
       "4  Sat Sep 17 17:08:24 +0000 2022   \n",
       "\n",
       "                                                                                                  user  \\\n",
       "0  (False, Thu Aug 05 18:44:26 +0000 2021, True, False, (She/her). Pansexual. Postgrad. Research in...   \n",
       "1  (False, Sat Nov 19 19:06:40 +0000 2011, False, False, SPORTS, 0, 151, 16, False, 416481014, 4164...   \n",
       "2  (False, Fri Dec 30 19:20:02 +0000 2011, True, False, 💜, 16721, 108, 254, False, 450871097, 45087...   \n",
       "3  (False, Thu Mar 12 10:36:22 +0000 2009, True, False, health care admin, happily married, 5 grand...   \n",
       "4  (False, Wed Feb 11 01:06:47 +0000 2009, False, False, Husband, Dog-Dude, Self-deprecating barkee...   \n",
       "\n",
       "               user_id               user_name  \\\n",
       "0  1423354181075673091        Debadrita Saha 🌈   \n",
       "1            416481014               HS SPORTS   \n",
       "2            450871097           Annabel bacon   \n",
       "3             23929337  Ira Greene 🌊♻️🌐☮️🌈🐰♋✡️   \n",
       "4             20562088               BrianCass   \n",
       "\n",
       "                                                                                      user_description  \\\n",
       "0  (She/her). Pansexual. Postgrad. Research int. at @decoloniszing. Former research int. @MCRG_CRG....   \n",
       "1                                                                                               SPORTS   \n",
       "2                                                                                                    💜   \n",
       "3  health care admin, happily married, 5 grandkids, progressive ex-hippie Deadhead still wonder wha...   \n",
       "4       Husband, Dog-Dude, Self-deprecating barkeep of @noirloungesf SFBay. @warriors @sfgiants @49ers   \n",
       "\n",
       "   followers_count  quote_count  \\\n",
       "0              430           73   \n",
       "1              151            0   \n",
       "2              108          341   \n",
       "3             2458            2   \n",
       "4              399            0   \n",
       "\n",
       "                                                                                      retweeted_status  \\\n",
       "0  (None, Fri Sep 16 15:41:50 +0000 2022, None, ([], None, [], [], []), None, None, 1335, False, lo...   \n",
       "1                                                                                                 None   \n",
       "2  (None, Sat Sep 17 01:51:48 +0000 2022, None, ([], None, [], [Row(display_url='twitter.com/i/web/...   \n",
       "3  (None, Sat Sep 17 16:32:08 +0000 2022, None, ([], None, [], [], []), None, None, 59, False, low,...   \n",
       "4                                                                                                 None   \n",
       "\n",
       "   retweet_count  favorite_count  \\\n",
       "0            112            1335   \n",
       "1              0               0   \n",
       "2           6556           21797   \n",
       "3             34              59   \n",
       "4              0               0   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  RT @StefanoBloch: Professors. You assign too much reading. It doesn't help. Assign less so stude...   \n",
       "1  Hamady vs Madison Academy | Today's Michigan High School Football Live Stream\\nWatch live Broadc...   \n",
       "2  RT @drsimonegold: BREAKING: A senior high school student at Holmes County High School in Florida...   \n",
       "3  RT @ungerbn103: Republicans will fund Abortion Bounty Hunters but they won't fund free School Lu...   \n",
       "4  @stoolpresidente Has a college QB ever had such a Cliff dive than Rattler.  Wasn’t he in the con...   \n",
       "\n",
       "   verified_user       user_location  \n",
       "0          False                None  \n",
       "1          False        Central Ohio  \n",
       "2          False                None  \n",
       "3          False  Baltimore, MD, USA  \n",
       "4          False       San Francisco  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = data_final.withColumn(\"user_location\",data_final.user.location)                       \n",
    "data_final.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "147614d9-42ee-4cff-85b2-41d38d266388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_final.write.format(\"parquet\").mode('overwrite').save('gs://msca-bdp-students-bucket/shared_data/suyashlakhani/tweets2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad000d-3858-4baa-942c-3497ffef1680",
   "metadata": {},
   "source": [
    "-->This is the final filtered dataframe containing the education related tweets and important columns for analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
